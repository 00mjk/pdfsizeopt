% by pts@fazekas.hu at Sat Jul 11 12:01:05 CEST 2009

\documentclass{ltugproc}
%\usepackage[latin2]{inputenc}% !! check
\usepackage{t1enc}
\usepackage{lmodern}
\usepackage{mflogo}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage[english]{babel}

\def\cmd{\textsf}
\def\pkg{\textsf}

%** Like \caption, but above the table, with \abovecaptionskip and
%** \belowcaptionskip swapped.
\def\captiontop#1{%
  \advance\abovecaptionskip-\belowcaptionskip
  \advance\belowcaptionskip\abovecaptionskip
  \advance\abovecaptionskip-\belowcaptionskip
  \abovecaptionskip-\abovecaptionskip
  \caption{#1}%
  \advance\abovecaptionskip-\belowcaptionskip
  \advance\belowcaptionskip\abovecaptionskip
  \advance\abovecaptionskip-\belowcaptionskip
  \abovecaptionskip-\abovecaptionskip
}


% Make \textunderscore and \_ shorter for font family lmr and lmss.
\makeatletter
\edef\pts@getfontfamily#1/#2/#3\hfuzz#4{\def#4{#2}}
\def\pts@@fontfamily@lmr{lmr}
  \edef\pts@@fontfamily@lmr{%
    \expandafter\strip@prefix\meaning\pts@@fontfamily@lmr}
\def\pts@@fontfamily@lmss{lmss}
  \edef\pts@@fontfamily@lmss{%
    \expandafter\strip@prefix\meaning\pts@@fontfamily@lmss}
%** Define #1 to the name of the active font family.
\def\pts@def@fontfamily#1{%
  \expandafter\expandafter\expandafter\pts@getfontfamily
      \expandafter\string\the\font///\hfuzz#1%
}
\let\pts@@orig@textunderscore\textunderscore
\DeclareRobustCommand\textunderscore{%
  \begingroup\pts@def@fontfamily\reserved@a
  \ifx\reserved@a\pts@@fontfamily@lmr
    \endgroup\vrule width1ex height0pt depth0.4pt\relax
  \else\ifx\reserved@a\pts@@fontfamily@lmss
    \endgroup\vrule width1ex height0pt depth0.4pt\relax
  \else
    \endgroup\pts@@orig@textunderscore
  \fi\fi
}



\author{P\'eter Szab\'o}
\title{Optimizing PDF output size of \TeX{} documents}

\begin{abstract}
There are several tools to generate PDF output from a \TeX{} document. By
choosing the appropriate tools and configuring them properly, it is possible
to reduce the PDF output size by a factor of 5 or even more, thus reducing
document download times, hosting and archiving costs. In the article we
enumerate the most common tools, and show how to configure them to reduce
the size of text, fonts and images embedded into the final PDF.

We also analyze image compression in detail, and present a new tool called
\cmd{pdfsizeopt} which optimizes the size of embedded images and Type\,1
fonts.
\end{abstract}

\begin{document}

\maketitle

\section{Introduction}

!!

!! Should I include ``This work was funded by my emplyer, Google.''??

\section{What does a PDF document contain}

PDF is a popular document file format designed for printing and on-screen
viewing. PDF faithfully preserves the design elements of the document, such
as fonts, line breaks, page breaks, exact spacing, text layout, vector
graphics and image resolution. Thus the author of a PDF document has precise
control over the document's appearance -- no matter what operating system or
renderer software is used for viewing or printing the PDF. From the viewer's
prespective, a PDF document is a sequence of rectangular pages containing
text, vector graphics and pixel-based images. In addition to that, some
rectangular page regions can be marked as hyperlinks, and Unicode
annotations can be added as well to the regions, so text can be copy-pasted
from the documents. (Usually the copy-paste yields only a sequence of
characters, with all formatting and positioning lost. Depending on the
software and the annotation, the bold and italics properties can be
preserved.) A table of contents can be added as well, which has a tree
structure, and each node of the tree consists of an unformatted caption and
a hyperlink within the document.

Additional features of PDF include forms (the user fills some fields with
data, clicks on the submit button, and the data is sent to a server in an
HTTP request), event handlers in JavaScript, embedded multimedia files,
encryption and access protection.

\section{How to create PDF}

Since PDF doesn't contain semantic information about the document (such as
in which order the document should be read, which regions are titles, how
are the tables built and how are the charts generated), word processors and
typesetting systems usually can export to PDF, but they have their own file
format which preserves semantics. PDF is usually not involved while the
author is composing (or typeseting) the document, but once a version of a
document is ready, a PDF can be exported and distributed. Should the author
distribute the document in the native file format of the word processor, he
might risk that the document doesn't get rendered as he intended, due to
software version differences or because slightly different fonts are
installed on the rendering computer, or the page layout settings in the word
processor are different.

Most word processors and drawing programs and image editors support
exporting as PDF. It is also possible to generate a PDF even if the software
doesn't have a PDF export feature. For example, it may be possible to
install a printer driver, which generates PDF instead of sending the
document to a real printer. (For example, on Windows, PDFCreator
\cite{pdfcreator} is such an open-source driver.) Some old programs can emit
PostScript, but not PDF. The \cmd{ps2pdf} \cite{ps2df} tool (part of
Ghostcript) can be used to convert the PostScript to PDF.

There are several options for PDF generation from
\TeX{} documents, including
pdf\TeX{}, \cmd{dvipdfmx} and \cmd{dvips} $+$ \cmd{ps2pdf}. Depending on how
the document uses hyperlinks and PostScript programming in graphics, some of
these would not work. See the details in Section~\ref{tex-to-pdf}.

\section{Motivation}

Our goal is to reduce the size of PDF files, focusing on those
created from \TeX{} documents. Having smaller PDF files reduces download
times, web hosting costs and storage costs as well. Although there is no
urgent need for reducing PDF storage costs is for personal use (since hard
drives in modern PCs are large enough), storage costs are significant for
publishing houses, print shops, e-book stores and hosting services,
libraries and archives \cite{multivalent-article}.
Usually lots of copies and backups are made of PDF
files originating from such places, saving 20\% of the file size right after
generating the PDF would save 20\% of all future costs associated with the
file.

Although e-book readers can store lots of documents (e.g.\ a 4\,GB e-book
reader can store 800 PDF books of 5\,MB average reasonable file size), they
get full quickly if we don't pay attention to efficient PDF generation. One
can easily get a PDF file 5 times larger than reasonable by using
inefficient software to generate it, or not setting the export settings
properly. Upgrading or changing the generator software is not always
feasible. A PDF recompressor becomes useful in these cases.

It is not our goal to propose or use
alternative file formats, which support a more
compact document representation or more agressive compression than PDF. An
example for such an approach is the Multivalent \emph{compact} file format
\cite{multivalent-compact}, which can be generated from a PDF using the
Multivalent tools, and it can be converted back to a regular PDF with these
tools as well. One of the merits of PDF is that it has a definitive, widely
accepted and implemented, freely available
specification \cite{pdfref} (and version 1.7 is
even ISO standard \cite{pdf-iso}), so if 20 years later we want to
print the document we've create today, then a well-documented and
standardized format such as PDF is a natural choice. (Please note, however,
that the PDF specification is not self-contained, it refers to other
specifications, e.g.\ for some compression algorithms and font formats.)
Another alternative document format is is DjVu (see in
Section~\ref{related-work}).

It is possible to save space in a PDF by removing non-printed information
such as hyperlinks, document outline elements, forms, text-to-Unicode
mapping or user annotations. Removing these does not affect the output when
the PDF is printed, but it degrades the user experience when the PDF is
viewed on a computer, and it may also degrade navigation and searchability.
Another option is to remove (unembed fonts). In such a case, the PDF viewer
will pick a font with similar metrics if the font is not installed on the
viewer machine. Please note that unembedding the font doesn't change the
horizontal distance between glyphs, so the page layout will remain the
same, but maybe glpyhs will look funny or hard-to-read. Yet another option
to save space is to reduce the resolution of the embedded images. We will
not use any of the techniques mentioned in this paragraph, because our goal
is to reduce redundancy and make the byte representation more effective,
while preserving visual and semantic information in the document.

\section{PDF file structure}

It is possible to save space in the PDF by serializing the same information
more efficiently and/or using better compression. This section gives a
high-level introductions to the data structures and their serialization in
the PDF file, focusing on size optimization. For a full description of the
PDF file format, see \cite{pdfref}.

PDF supports integer, real number, boolean, null, string and name as
simple data types. A string a sequence of 8-bit bytes. A name is also a
sequence of 8-bit bytes, usually a concatenation of a few English words in
CamelCase, often used as a dictionary key (e.g. \texttt{/MediaBox}) or an
enumeration value (e.g. \texttt{/DeviceGray}). Composite data types are the
list and the dictionary. A dictionary is an unordered sequence of key--value
pairs, where keys must be names. Values in dictionaries and list items can
be primitive or composite. There is a simple serialization of values to
8-bit strings, compatible with PostScript LanguageLevel\,2. For example,
\texttt{\hbox{<}</Integer 5 /Real -6.7 /String ((C)2009\textbackslash))
/StringInHex <Face> /Null null
/Boolean true /Name /Foo /List [3 4 5]\hbox{>}>} defines a dictionary
containing values of various types. All data types are immutable.

It is possible to define a value for future use by defining an
\emph{object.} For example, \texttt{12 0 obj [/PDF/Text] endobj} defines
object number 12 to be an array of two items (\texttt{/PDF} and
\texttt{/Text}). The number 0 in the definition is the so-called generation
number, referring to version of the incrementally updated PDF file this
object was created in. Since most of the tools just create a new PDF instead
of updating parts of an existing one, we can assumme for simplicity that the
generation number is always zero. Once an object is defined it is possible
to refer to it (e.g.\ \texttt{12 0 R}) instead of typing its value. It is
possible to define self-referential lists and dictionaries using object
definitions. The PDF specification requires some PDF structure elements
(such as the \texttt{/FontDescriptor} value) be an indindirect reference,
i.e.\ defined as an object. Such elements cannot be inlined into other
object, but they must be referred to.

A PDF file contains a header, a list of objects, a \emph{trailer}
dictionary, cross-reference information (offsets of object definitions,
sorted by object number), and the end-of-file marker. The header contains
the PDF version (PDF-1.7 being the latest). All of the file elements above
except for the PDF version, the list of objects and the trailer are
redundant, and can be regegenerated if lost. The parsing of the PDF starts
at the trailer dictionary. Its \texttt{/Root} value refers to the catalog
dictionary object, whose \texttt{/Pages} value refers to a dictionary object
containing the list of pages. The interpretation of each object depends on
the reference path which leads to that object from the trailer. In addition
to that, dicitionary objects may have the \texttt{/Type} and/or
\texttt{/Subtype} value indicating the interpretation. For example,
\texttt{\hbox{<}</Subtype/Image ...\hbox{>}>} defines a pixel-based image.

In addition to the data types above, PDF supports streams as well. A
\emph{stream} object is a dictionary augmented by the stream data, which is
a byte sequence. The syntax is \texttt{... ... obj << ... >> stream ...
endstream endobj}, where the stream data starts right after the keyword
\texttt{stream}. The stream data can be compressed or otherwise encoded
(such as in hex). The \texttt{/Filter} and \texttt{/DecodeParms} values in
the dictionary specify how the uncompress/\allowbreak decode the stream data.
It possible the specify multiple uncompress/\allowbreak decode filters,
e.g.\ \texttt{/Filter [/ASCIIHexDecode /FlateDecode]} says that the bytes
aftter \texttt{stream} should be decoded as a hex string, and then
uncompressed using PDF's ZIP implementation. (Please note that the use of
\texttt{/ASCIIHexDecode} is just a waste of space unless one wants to create
an ASCII PDF file.) The three most common uses for
streams are: image pixel data, embedded font files and content streams.
A content stream contains the instructions to draw the contents of page. The
stream data is ASCII, with a syntax similar to PostScript, but with
different operators. For example, \texttt{BT/F 20 Tf 1 0 0 1 8 9
Tm(Hello world)Tj ET} in a content stream draws the text ``Hello World''
with the font \texttt{/F} at size 20 units, shifted up by 8 units, and
shifted right by 9 units (according to the transformation matrix
\texttt{1 0 0 1 8 9}).

Streams can use the following generic compression methods: ZIP (also called
as flate), LZW and run-length encoding. ZIP is almost always superior. In
addition to those, PDF supports some image-specific compression methods as
well: JPEG and JPEG2000 for true-color images and JBIG2 and G3 fax (also
called as CCITT fax) for bilevel (two-color) images. JPEG and JPEG2000 are
lossy methods, they usually yield the same size at the same quality
settings -- but JPEG2000 is more flexible. JBIG2 is superior to G3 fax and
ZIP for bilevel images. Any number of compression filters can be applied to
a stream, but usually applying more than one yields a larger compressed
stream size than just applying one. ZIP and LZW support predicors as well. A
predictor is an easy-to-compute, invertible filter which is applied to the
stream data before compression, to make the data more compressible. One
possible predictor subtracts the previous data value from the current one,
and sends the difference to the compressor. This helps reducing the file
size if the difference between adjacent data values is small most of the
time. This is true for some images with a few number of colors.

There is cross-reference information near the end of the PDF file, which
contains the start byte offset of all object definitions. Using this
information it is possible to render parts of the file, without reading the
whole file. The most common format for cross-reference information is the
\emph{cross-reference table} (starting with the keyword \texttt{xref}). Each item
in the table consumes 20 bytes, and contains an object byte offset. The
object number is encoded by the position of the item. For PDFs with several
thousand objects, the space occupied by the cross-reference table is is not
negligable. PDF\,1.5 introduces \emph{cross-reference streams,} which store
the cross-reference information in compact form in a stream. Such streams
usually compressed as well, using ZIP and a predictor. The benefit of the
predictor is that adjacent offsets are close to each other, so their
difference will contain lots of zeroes, which can be compressed efficiently.

Compression cannot be applied to the PDF file as a whole, only individual
parts (such as stream data and cross-reference information) can be
compressed. However, there can be lots of small object definitions in the
file which are not streams. To compress those, PDF\,1.5 introduces
\emph{object streams.} The data in an object stream contains a concatenation
of any number of non-stream object definitions. Object streams can be
compressed just as regular stream data. This makes it possible to squeeze
repetitions spanning over multiple object definitions. Thus, with PDF\,1.5,
most of the PDF file can be stored in compressed streams. Only a few dozen
byte of headers and end-of-file markers, and the stream dictionaries remain
uncompressed.

\section{How to compile a \TeX{} document to a small PDF}\label{tex-to-pdf}

This section enumerates the most common tools which can generate a PDF from
a \texttt{.tex} source, explains how to enforce the proper compression and
font settings, and gives advice how to prepare vector and pixel-based images
so they don't become unnecessarily large.

\paragraph{Pick the best PDF generation method}
Table~\ref{tab:method-feature} lists features of the 3 most common methods
(also called as \emph{drivers}) which produce a PDF from a \TeX{} document,
and Table~\ref{tab:texbook-to-pdf} compares the file size whey produce when
compiling the \TeX{}book. There is no single best driver because of the
different feature sets, but looking at how large the output of \cmd{dvips}
is, the preliminary conclusion would be to use pdf\TeX{}
or \cmd{dvipdfm(x)} except if advanced PostScript features are needed (such
as for \pkg{psfrag} and \pkg{pstricks}).

\begin{table}
\captiontop{Output file sizes of PDF generation from The \TeX{}book, with
various methods. The PDF was optimized with \cmd{pdfsizeopt.py}, then with
Multivalent}\label{tab:texbook-to-pdf}
\par\small\noindent\hfil
\begin{tabular}{@{}lrr@{}}
\toprule
                  &&\emph{optimized}\\
\emph{method}     &\emph{PDF bytes}&\emph{PDF bytes}\\\midrule
pdf\TeX           &2283510 &1806887\\
\cmd{dvipdfm}     &2269821 &1787039\\
\cmd{dvipdfmx}    &2007012 &1800270\\
\cmd{dvips}$+$\cmd{ps2pdf}      &3485081 &3181869\\
\bottomrule
\end{tabular}
\end{table}

\begin{table}
\captiontop{Features supported by various PDF output
methods}\label{tab:method-feature}
\par\small\noindent\hfil
\begin{tabular}{@{}llll@{}}
\toprule
\emph{Feature}        & pdf\TeX   & \cmd{dvipdfm(x)} & \cmd{dvips} \\\midrule
\pkg{hyperref}        & +         & +                & +           \\
TikZ                  & +         & +                & +           \\
\pkg{beamer.cls}      & +         & $+^o$            & $+^u$       \\
include PDF           & +         & $+^b$            & +           \\
embed bitmap font     & +         & +                & +           \\
embed Type\,1 font    & +         & +                & +           \\
[2ex]
embed TrueType font   & +         & +                & $-$         \\
include EPS           & $-$       & +                & +           \\
include JPEG          & +         & $+^x$            & $-$         \\
include PNG           & +         & $+^x$            & $-$         \\
include \MP           & $+^m$     & $+^m$            & $+^r$       \\
\pkg{psfrag}          & $-^f$     & $-^f$            & +           \\
\pkg{pstricks}        & $-^f$     & $-^f$            & +           \\
\pkg{pdfpages}        & +         & $-$              & $-$         \\
line break in link    & +         & +                & $-$         \\
\bottomrule
\end{tabular}
\par\bigskip
\par\noindent \emph{b:} bounding box detection with \cmd{extractbb} or
  \pkg{pts-graphics-helper}
\par\noindent \emph{f:} see \cite{pstricks-pdfoutput} for workarounds
\par\noindent \emph{m:} convenient with \texttt{\string\includegraphicsmps}
  defined in \pkg{pts-graphics-helper}
\par\noindent \emph{r:} rename file to \texttt{.eps} manually
\par\noindent \emph{o:} with \texttt{\string\documentclass[dvipdfm]\{beamer\}}
\par\noindent \emph{u:} use \texttt{dvips -t unknown doc.dvi} to get the paper
size right.
\par\noindent \emph{x:} with \texttt{\string\usepackage[dvipdfmx]\{graphics\}}
  and shell escape running \cmd{extractbb}
\end{table}

We continue with presenting and analyzing the methods mentioned.

\begin{description}

\item[dvips] This approach converts
\TeX{} source $\to$ DVI $\to$ PostScript $\to$ PDF,
using \cmd{dvips} \cite{dvips} for creating the PostScript file, and
\cmd{ps2pdf} (part of Ghostscript) for creating the PDF file. Example
command-lines for compiling \texttt{doc.tex} to \texttt{doc.pdf}:
\begin{verbatim}
$ latex doc
$ dvips doc
$ ps2pdf14 doc.ps
\end{verbatim}%$

\item[dvipdfmx] The tool \cmd{dvipdfmx} \cite{dvipdfmx} converts from
DVI to PDF, producing a very small output file. \cmd{dvipdfmx} is part of \TeX{}\,Live 2008, but since it's
quite new, it may be missing from other \TeX{} distributions. Its
precedessor, \cmd{dvipdfm} has not been updated since March 2007. Notable
new features in \cmd{dvipdfmx} are: support for non-latin scripts and fonts;
emitting the Type\,1 fonts in CFF (that's the main reason for the size
difference in Table~\ref{tab:method-feature}); parsing pdf\TeX{}-style font
\texttt{.map} files. Example command-lines:
\begin{verbatim}
$ latex doc
$ dvipdfmx doc
\end{verbatim}

\item[pdf\TeX] The commands \cmd{pdftex} or \cmd{pdflatex}  \cite{pdftex}
generate PDF directly from the \texttt{.tex} source, without any intermediate
files. An important advantage of pdf\TeX{} over the other methods is that it
integrates nicely with the editors \TeX{}\-Shop and \TeX{}works. The
single-step approach ensures that there would be no glitches
(e.g.\ images misaligned or not properly sized)
because the tools are not integrated properly.
Example command-line:
\begin{verbatim}
$ pdflatex doc
\end{verbatim}%$
~

\end{description}

\noindent The command \texttt{latex doc} is run for both \cmd{dvips} and
\cmd{dvipdfm(x)}. Since these two drivers expect a bit different
\texttt{\string\special}s in the DVI file, the driver name has to be
communicated to the \TeX{} macros generating the \texttt{\string\special}s.
For \LaTeX{}, \cmd{dvips} is the default. To get \cmd{dvipdfm(x)} right,
pass \texttt{dvipdfm} (or \texttt{dvipdfmx}) as an option to
\texttt{\string\documentclass} or to both
\texttt{\string\usepackage\{graphicx\}} and
\texttt{\string\usepackage\{hyperref\}}. Loading the package
\pkg{pts-graphics-helper} \cite{pts-graphics-helper} sets up \cmd{dvipdfm}
as default unless the document is compiled with \cmd{pdflatex}.

Unfortunately, some graphics packages (such as \pkg{psfrag} and
\pkg{pstricks}) require a PostScript backend such as \cmd{dvips},
and pdf\TeX{} or \cmd{dvipdfmx} don't provide that. See
\cite{pstricks-pdfoutput} for a list of workarounds. They rely running
\cmd{dvips} on the graphics, possibly converting its output to PDF, and then
including those files in the main compilation. Most of the extra work can be
avoided if graphics are created as external PDF files (without text
replacements), TikZ \cite{tikz} figures or \MP{} figures. TikZ and \MP{}
support text captions typeset by \TeX{}. Inkscape users can use
\pkg{textext} \cite{textext} within Inkscape to make \TeX{} typeset the
captions.

The \texttt{\string\includegraphics} command of the standard \pkg{graphicx}
\LaTeX{}-package accepts a PDF as the image file. In this case, the first
page of the specified PDF will be used as a rectangular image. With
\cmd{dvipdfm(x)}, one also needs a \texttt{.bb} (or \texttt{.bbx}) file
containing the bounding
box. This can be generated with the \cmd{extractbb} command, shipping with
\cmd{dvipdfm(x)}. Or, it is possible to use the \pkg{pts-graphics-helper}
package \cite{pts-graphics-helper}, which can find the PDF bounding box
directly (most of the time).

\pkg{dvipdfm(x)} contains special support for embedding figures created by
\MP{}. For pdf\TeX{}, the \pkg{graphicx} package loads \pkg{supp-pdf.tex},
which can parse the output of \MP{}, and embed it to the document.
Unfortunately, the \pkg{graphicx} package is not smart enough to recognize
\MP{} output files (\texttt{jobname.1}, \texttt{jobname.2} etc.) by
extension. The \pkg{pts-graphics-helper} package \cite{pts-graphics-helper}
overcomes this limitation by defining \texttt{\string\includegraphicsmps},
which can be used in place of \texttt{\string\includegraphics} for including
figures created by \MP{}. The packages works consistently with
\pkg{dvipdfm(x)} and pdf\TeX{}.

With pdf\TeX{}, it is possible to embed page regions from an external PDF,
using the \pkg{pdfpages} \LaTeX{}-package. Please note that due to a
limitation in pdf\TeX{}, hyperlinks and outlines (table of contents) in the
embedded PDF will be lost.

Although \cmd{dvipdfm(x)} supports PNG and JPEG image inclusion, calculating
the bounding box may be cumbersome. It is recommended that all external
images should be converted to PDF first. The recommended software for that
conversion is \cmd{sam2p} \cite{sam2p}, which creates a small PDF (or EPS)
quickly.

Considering all of the above, we recommend using pdf\TeX{} for compiling
\TeX{} documents to PDF. If, for some
reason, using pdf\TeX{} is not feasible, we recommend \cmd{dvipdfmx} from
\TeX{}\,Live 2008 or later. If a 1\% decrease in file size is worth the
trouble of getting fonts right, we we recommend \cmd{dvipdfm}.
In all the cases above, the final PDF should be optimized with
\cmd{pdfsizeopt.py} (see later).

\paragraph{Set the ZIP compression level to maximum}

For pdf\TeX{}, the assignment \texttt{\string\pdfcompresslevel9} select
maximum PDF compression. With \TeX{}\,Live 2008, this is the default. Here
is how to specify it on the command-line:
\texttt{pdflatex "\string\pdfcompresslevel9 \string\input" doc}.
For \cmd{dvipdfm(x)}, the command-line flag \texttt{-z9} can be used to
maximize compression. This is also the default.

Please note that PDF supports redundancy elimination in many different
levels (see in Section~\ref{existing}). Setting the ZIP compression level is
only one of those.

\paragraph{Generate object streams and cross-reference streams}

pdf\TeX{} can generate object streams and cross-reference streams to save
about 10\% of the PDF file size, or even more if the file contains lots of
hyperlinks. (The actual saving depends on the file
structure.) Example command-line for enabling it:
\texttt{pdflatex "\string\pdfminorversion5 \string\pdfobjcompresslevel3
\string\input" doc}. Please note, however, that if you optimize with
Multivalent (see in Section~\ref{optimize}), setting this doesn't
make any difference, because Multivalent will emit more efficient streams
anyway.

\paragraph{Get rid of complex graphics}

Some computer algebra programs and vector modeling tools emit very large
PDF (or similar vector graphics) files. This can be because they draw the
graphics of too many little parts (e.g.\ they draw a sphere using several
thousand triangles), or they draw too many parts which would
be invisible anyway, because other parts cover them. Converting or
optimizing such PDF files usually doesn't help, because the optimizers are not
smart enough to rearrange the drawing instructions, and then skip some of
them. A good rule of thumb is that if a figure in an optimized PDF file is
larger than the corresponding PNG file rendered in 600\,DPI, then the
figure is too complex. To reduce the file size, it is recommended to 
export the figure as a PNG (or JPEG) image from the program, and embed that
bitmap image.

\paragraph{Downsample high-resolution images}

For most printers it doesn't make a visible difference to print in a
resolution higher than 600\,DPI. Sometimes even the difference between
300\,DPI and 600\,DPI is negligable. So converting the embedded images down
to 300\,DPI may save significant space without too much quality degradation.
Downsampling before the image is included is a bit of manual work
for each image, but there are lot of free software tools to do that (such as
GIMP \cite{gimp} and the \cmd{convert} tool of ImageMagick \cmd{imagemagick}).
It is possible to downsample after the PDF has been created, for example
with the commercial software PDF Enhancher \cite{pdf-enhancer} or Adobe
Acrobat. \cmd{ps2pdf}
(using Ghostscript's \texttt{-dDEVICE=pdfwrite} \cite{pdfwrite-params}) can
read PDF files, and downsample images within as well, but it usually grows
other parts of the file too much (15\% increase in file size for The
\TeX{}book), and it may lose some information (it does
keep hypherlinks and the document outline, though).

\paragraph{Crop large images}

If only parts of a large image contain useful and relevant information, one
can save space by cropping the image.

\paragraph{Choose the JPEG quality}

When using JPEG (or JPEG2000) compression, there is a dradeoff between
quality and file size. Most JPEG encoders based on libjpeg accept an integer
quality value between 1 and 100. For true color photos, a quality below 40
produces a severely degraded, hard-to-recognize image, with 75 we get some
harmless glitches, and with 85 the degradation is hard to notice. If the
document contains lots of large JPEG images, it is worth reencoding those
with a lower quality setting to get a smaller PDF file. PDF enhancer can
reencode JPEG images in an existing PDF, but sometimes not all the images
hae to be reencoded. With GIMP it is possible to get a real-time preview of
the quality degradation before saving, by moving the quality slider.

Please note that some cameras don't encode JPEG files efficiently when
saving to the memory card, and it is possible to save a lot of space by
reencoding on the computer, even with high quality settings.

\paragraph{Embed vector fonts instead of bitmap fonts}

Most fonts used with \TeX{} nowadays are available in Type\,1 vector format.
(These fonts include the Computer Modern families, the Latin Modern families,
the URW versions of the base 14 and some other Adobe fonts,
the \TeX{} Gyre families, the Vera families, the Palatino family, the
corresponding math fonts, and some symbol and drawing fonts.) This is a
signifcant shift from the original \TeX{} (+ \cmd{dvips}) concept, which used
bitmap fonts generated by \MF{}. While drivers still support embedding
bitmap fonts to the PDF, this is not recommended, because bitmaps (at 600
DPI) are larger than their vector equivalent, they render more slowly and
they look uglier in some PDF viewers.

\begin{table}
\captiontop{Font \texttt{.map} files used by various drivers and their
symlink targets (default first) in \TeX{}\,Live 2008}\label{tab:mapfiles}
\par\small\noindent\hfil
\begin{tabular}{@{}ll@{}}
\toprule
\emph{Driver} & Font \texttt{.map} file\\
\midrule
\cmd{xdvi} & \pkg{ps2pk.map} \\
\cmd{dvips}& \pkg{psfonts.map} $\to$\\
           & \pkg{psfonts\_t1.map} $|$ (\pkg{psfonts\_pk.map}) \\
pdf\TeX{}  & \pkg{pdftex.map} $\to$\\
           & \pkg{pdftex\_dl14.map} $|$ (\pkg{pdftex\_ndl14.map}) \\
\cmd{dvipdfm(x)}& \pkg{dvipdfm.map} $\to$\\
                & \pkg{dvipdfm\_dl14.map} $|$ (\pkg{dvipdfm\_ndl14.map}) \\
\bottomrule
\end{tabular}
\end{table}

If a font is missing from the font \texttt{.map} file, drivers tend to
generate a bitmap font automatically, and embed that. To make sure this
didn't happen, it is possible detect the presence of bitmap fonts in a PDF
by running \texttt{grep -a "/Subtype */Type3" doc.pdf}. Here is how to
instruct pdf\TeX{} to use bitmap fonts only (for debugging purposes):
\texttt{pdflatex "\string\pdfmapfile{}\string\input" doc}.
The most common
reason for the driver not finding a corresponding vector font is that the
\texttt{.map} file is wrong or the wrong map file is used. With
\TeX{}\,Live, the \cmd{updmap} tool can be used to regenerate the
\texttt{.map} files for the user, and the \cmd{updmap-sys} command
regenerates the system-level \texttt{.map} files. Table~\ref{tab:mapfiles}
shows which driver reads which \texttt{.map} file. Copying over
\pkg{pdftex\_dl14.map} to the current directory as the driver-specific
\texttt{.map} file
usually makes the driver find the font. Old \TeX{} distributions had quite
a lot of problems finding fonts, upgrading to \TeX{}Live\,2008 or newer is
strongly recommended.

Some other popular fonts (such as the Microsoft web fonts) are available in
TrueType, which is another vector format. \cmd{dvipdfm(x)} and pdf\TeX{} can
embed TrueType fonts, but \cmd{dvips} can't (it just dumps the
\texttt{.ttf} file to the \texttt{.ps} file, rendering it unparsable).

OpenType fonts with advanced features such as script and feature selection
and glyph substitution are supported by Unicode-aware \TeX{}-derivatives
such as \XeTeX{}. \cmd{dvipdfmx} also supports OpenType fonts.

\paragraph{Encode Type\,1 fonts as CFF}

CFF \cite{cff} is an alternative, compact, highly compressible binary font
format that can represent Type\,1 font data without loss. By embedding
vector fonts in CFF (\texttt{/Subtype /Type1C}) instead of Type\,1, one can
save significant portion of the PDF file, especially if the document is 10
pages or less (e.g.\ reducing the PDFfile size from 200\,kB to 50\,kB).
\cmd{dvipdfmx} does this by default, the other drivers (pdf\TeX{},
\cmd{dvipdfm}, \cmd{ps2pdf} with \cmd{dvips}) don't support CFF embedding so
far. If you optimize the PDF with \cmd{pdfsizeopt.py}, you don't have to pay
attention to CFF embedding, because \cmd{pdfsizeopt.py} converts Type\,1
fonts in the PDF to CFF.

\paragraph{Omit the base 14 fonts} The base 14 fonts are Times (in 4 styles,
Helvetica (in 4 styles), Courier (in 4 styles), Symbol and Zapf Dingbats.
To reduce the size of the PDF, it is possible to omit them from the
PDF file, because PDF viewers tend to have them. However, omitting the base 14
fonts is deprecated since PDF\,1.5. Adobe Reader 6.0 or newer,
and other PDF viewers (such as \cmd{xpdf} and \cmd{evince}) don't contain
those fonts either, but they can find them as system fonts. On Debian-based
Linux systems, those fonts are in the \pkg{gsfonts} package.

In \TeX\,Live, the directives \emph{pdftexDownloadBase14} and
\emph{dvipdfmDownloadBase14} etc.\ in the config file
\texttt{texmf-config/web2c/updmap.cfg} specify whether to embed the base 14
fonts. After modifying this config file (either the system-wide or the one in
\texttt{\$HOME/.texlive2008}) and running the \cmd{updmap} command, the
following font map files would be created:

\begin{description}

\item[pdftex\_dl14.map] Font map file for pdf\TeX{} with the base 14 fonts
  embedded. This is the default.
\item[pdftex\_ndl14.map] Font map file for pdf\TeX{} with the base 14 fonts
  omitted.
\item[pdftex.map] Font map file used by pdf\TeX{} by default.
Identical to one of the two above, based on the
\emph{pdftexDownloadBase14} setting.
\item[dvipdfm\_dl14.map] Font map file for \cmd{dvipdfm(x)} with the base 14
  fonts embedded. This is the default.
\item[dvipdfm\_ndl14.map] Font map file for \cmd{dvipdfm(x)} with the base 14
  fonts omitted.
\item[dvipdfm.map] Font map file used by \cmd{dvipdfm(x)} by default.
Identical to one of the two above, based on the
\emph{dvipdfmDownloadBase14} setting.

\end{description}

It is possible to specify the base 14 embedding settings without modifying
config files or generating \texttt{.map} files. Example command-line for
pdf\TeX{}: \texttt{pdflatex "\string\pdfmapfile{pdftex\_ndl14.map}\string\input"
doc.tex}.
However, this will display a warning \emph{No flags specified for
non-embedded font}. To get rid of this, use
\texttt{pdflatex "\string\pdfmapfile{=pdftex\_ndl14\_extraflag.map}\string\input"
doc.tex}
instead. Get the \texttt{.map} file from \cite{pdfsizeopt-extra}.

The \texttt{.map} file syntax for \cmd{dvipdfm} is different, but
\cmd{dvipdfmx} can use a \texttt{.map} file of pdf\TeX{} syntax. Example:
\texttt{dvipdfmx -f pdftex\_dl14.map doc.dvi}. Please note that
\cmd{dvipdfm} loads the \emph{.map} files specified in \pkg{dvipdfmx.cfg}
first, and the \texttt{.map} files loaded with the \texttt{-f} flag override
entries loaded previously, from the config file. To have the base 14 fonts
omitted, run \texttt{dvipdfmx -f pdftex\_ndl14.map -f
dvipdfmx\_ndl14\_extra.map dok.tex}. Get the last \texttt{.map} file from
\cite{pdfsizeopt-extra}. Without \pkg{dvipdfmx\_ndl14\_extra.map}, a bug in
\cmd{dvipdfm} prevents it from writing a PDF file without the font -- it
would embed a rendered bitmap font instead.

\paragraph{Disable font subsetting before concatenation}

!! (not an option most of the time)

\section{How to save space in an existing PDF}\label{existing}

!! give details
!! table on who implements what
!! what is new work in pdfsizeopt.py
!! what does pdflatex and dvipdfm implement

\paragraph{Use cross-reference streams and compress them with the $y$-predictor}

Each offset entry in an (uncompressed) cross-reference table consumes 20
bytes. This can be reduced by using compressed cross-reference streams, and
enabling the $y$-predictor. A reduction factor of 180 is possible if the
PDF file contains many objects (e.g.\ more than $10^5$ objects in
\emph{pdfref}, with less than 12000 bytes in the cross-reference stream).

The reason why the $y$-predictor can make a difference of a factor of 2 or
even more is the following.
The $y$-predictor encodes each byte in a rectangular array of bytes by
subtracting the original byte above the current byte from the current byte.
So if each row of the rectangular array contains an object offset, and the
offsets are increasing, then most of the bytes in the output of the
$y$-predictor would have a small absolute value, mostly zero. Thus the
output of the $y$-predictor can be compressed more efficiently with ZIP than
the original byte array.

Some tools such as Multivalent implement the $y$-predictor with PNG
predictor 12, but using TIFF predictor 2 avoids stuffing in the extra byte
per each row -- \cmd{pdfsizeopt.py} does that.

\paragraph{Use object streams}

It is possible to save space in the PDF by concatenating small (non-stream)
objects to an object stream, and compressing the stream as a whole. One can
even sort objects by type first, so similar objects will be placed next to
each other, and they will fit to the 32\,kB long ZIP compression window.

Please note that both object streams and cross-reference streams are
PDF\,1.5 features, and cross-reference streams must be also used when object
streams are used.

\paragraph{Use better stream compression}

In PDF any stream can be compressed with any compression filter (or a
combination of filters). ZIP is the most efficient general-purpose
compression, which is recommended for compressing content streams, object
streams, cross-reference streams and font data streams (such as CFF).
For images, however, there are specialized filters (see later in this
section).

Most PDF generators (such as \cmd{dvipdfm(x)} and pdf\TeX{}) and
optimization tools (such as Multivalent)
use the \pkg{zlib} code for general-purpose ZIP compression.
\pkg{zlib} lets the user specify the \emph{effort} parameter between 0 (no
compression) and 9 (slowest compression, smallest output) to balance
compression speed versus compressed data size. There are, however
alternative ZIP compressor implementations (such as KZIP \cite{kzip}), which
privide an even higher effort -- but the author doesn't know of any PDF
optimizers using those algorithms.

\paragraph{Recompress images}

\paragraph{Unify duplicate objects}

\paragraph{Reorganize content streams}

\paragraph{Remove unnecessary indirect references}

\paragraph{Remove duplicate images, based on pixel value}

\paragraph{Convert Type\,1 fonts to CFF}

!! \texttt{/Subtype/Type1C}
pdf\TeX{} and \cmd{dvipdfm} create Type\,1; dvipdfmx creates Type\,1C.

\paragraph{Unify font subsets}

\paragraph{Remove data ignored by the PDF specification}

\paragraph{Omit explicitly specified default values}

\paragraph{Convert hex strings to binary}

\paragraph{Escape only if necessary in strings}

\paragraph{Remove unused objects}

\paragraph{Remove page thumbnails}

\paragraph{Subset fonts}

\paragraph{Unify subsets of the same font}

\paragraph{Convert some inline images to objects}

\paragraph{Remove ASCII-based filters}

!! ASCIIHexDecode shorter

\paragraph{Serialize values more efficiently}

!! ASCII-repr string hex shorter
!! get rid of spaces

\section{PDF size optimization tools}

\begin{table*}
\captiontop{PDF size reduction by object type, when running
\cmd{pdfsizeopy.py} + Multivalent}\label{tab:psom-by-type}
\par\small\noindent\hfil
% !! make this table less wide, avoid overfull \hbox
\begin{tabular}{@{}lrrrrrr@{}}
\toprule
\emph{document} & \emph{contents} & \emph{font} & \emph{image} & \emph{other} & \emph{xref} & \emph{total} \\\midrule
cff & $141153-01$\% & $25547-01$\% & 0 & $178926-90$\% & $174774-99$\% & $521909-64$\% \\
beamer1 & $162423-01$\% & $44799-53$\% & $115160+00$\% & $453098-94$\% & $56752-97$\% & $832319-61$\% \\
eu2006 & $964248+00$\% & $3271206-90$\% & $3597779-05$\% & $531968-64$\% & $45792-93$\% & $8411464-42$\% \\
inkscape & $10676317-19$\% & $230241+00$\% & $6255203-19$\% & $946108-78$\% & $122274-93$\% & $18245172-23$\% \\
lme2006 & $1501584-13$\% & $314265-72$\% & $678549-05$\% & $176666-90$\% & $31892-92$\% & $2703119-24$\% \\
pdfref & $6269878-04$\% & $274231-03$\% & $1339264+00$\% & $17906915-78$\% & $6665536-99$\% & $32472771-64$\% \\
pgf2 & $2132674+00$\% & $275768-50$\% & 0 & $1183749-83$\% & $190832-95$\% & $3783193-35$\% \\
texbook & $1507901+00$\% & $519550-47$\% & 0 & $217616-83$\% & $35532-86$\% & $2280769-20$\% \\
tuzv & $112145-02$\% & $201155-83$\% & 0 & $21913-76$\% & $2471-87$\% & $337764-56$\% \\
\bottomrule
\end{tabular}
\par\bigskip
\par\noindent All numeric values are in bytes. !!
\end{table*}

\subsection{Test PDF files}

In order to compare the optimization efficiency of the tools presented in
this section, we have compiled a set of test PDF files, and optimized them
with each tool. The \emph{totals} column of Table~\ref{psom-by-type} shows
the size of each file (the $+$ and $-$ percentages can be ignored now), and
other columns show the bytes used by different object types. The test files
can be downloaded from \cite{example-pdfs}. Some more
details about the test files:

\begin{description}

\item[cff] 62-page technical documentation about the CFF file format. Font
data is a mixture of Type\,1, CFF and TrueType. Compiled with FrameMaker
7.0, PDF generated by Acrobat Distiller 6.0.1. 

\item[beamer1] 75 slide-steps long presentation created with
\pkg{beamer.cls} \cite{beamer}; containing hyperlinks, math formulas, some
vector graphics and a few pixel-based images. Compiled with pdf\TeX{}.
Font data is in Type\,1 format.

\item[eu2006] 126-page conference proceedings (of Euro\TeX{} 2006)
containing some large images. Individual articles were compiled with
pdf\TeX{}, and then PDF files were concatenated. Because of the
concatenation, many font subsets were embedded multiple times, so a large
part of the file is font data. Font data is a mixture of Type\,1 and CFF.

\item[inkscape] 341-page software manual with lots of screenshots and small
images created with codeMantra \cite{codemantra}. Font data is a mixture of
Type\,1, CFF and TrueType.

\item[lme2006] 240-page conference proceedings in Hungarian, containing some
black-and-white screenshot images. Individual articles were compiled with
\LaTeX{} and \cmd{dvips} (without font subsetting), and the PostScript files
were concatenated and converted to PDF in a single run of a modified
\cmd{ps2pdf}. Since font subsetting was disabled in \cmd{dvips}, later
\cmd{ps2pdf} was able to subset fonts without duplication. Font data is in
CFF.

\item[pdfref] 1310-page reference manual about PDF\,1.7 containing quite a
lot of duplicate xref tables and XML metadata about document parts.
Optimization gets rid of both the duplicate xref tables and the XML
metadata. Font data is in CFF. Compiled with FrameMaker 7.2, PDF generated
by Acrobat Distiller 7.0.5.

\item[pgf2] 560-page software manual about TikZ, with lots of vector
graphics as examples, with an outline, without hyperlinks. Compiled with
pdf\TeX{}. Font data is in Type\,1 format.
!! did pdfe help in getting vector graphics smaller?

\item[texbook] 494-page user manual about \TeX{} (The \TeX{}book), compiled
with pdf\TeX{}. No pixel images, and hardly any vector graphics.

\item[tuzv] Mini novel in Hungarian, typeset on 20 A4 pages in a 2-column
layout, compiled with \cmd{dvipdfm}. It contains no images or graphics. Font data
is in Type\,1 format.

\end{description}

\noindent None of the test PDF files used cross-reference streams or object streams.

\subsection{ps2pdf}

!!

\begin{table}
\captiontop{PDF optimization efficiency
of PDF Enhancer}\label{tab:eff-pdfe}
\par\small\noindent\hfil
\advance\tabcolsep-2pt  % Prevent overfull \hbox.
\begin{tabular}{@{}lrrrr@{}}
\toprule
% !! why is Multivalent alone better on pdf_reference_1-7? what about extra
%    compression
\emph{document} & \emph{input} & \emph{pdfe} & \emph{epsom} & \emph{psom} \\\midrule
cff         &   521909 &   229953 &   174182 &   180987 \\
beamer1     &   832319 &   756971 &   296816 &   317351 \\
eu2006      &  8411464 &  failed  & n/a      &  4812306 \\
inkscape    & 18245172 & 14613044 & 12289136 & 13944481 \\
lme2006     &  2703119 &  2263227 &  1781574 &  2033582 \\
pdfref      & 32472771 & 23794114 & 11009960 & 11237663 \\
pgf2        &  3783193 &  3498756 &  2245797 &  2438261 \\
texbook     &  2280769 &  2273410 &  1803166 &  1806887 \\
tuzv        &   337764 &   338316 &   147453 &   146414 \\
\bottomrule
\end{tabular}
\par\bigskip
\par\noindent All numeric values are in bytes.
\par\noindent\emph{pdfe:} PDF Enhancer 3.2.5 (1122r) server edition
\par\noindent\emph{epsom:} PDF Enhancer $+$ \cmd{pdfsizeopt.py} $+$ Multivalent
\par\noindent\emph{psom:} \cmd{pdfsizeopt.py} $+$ Multivalent
\end{table}


\subsection{PDF Enhancer}

!! menu name: Adobe Acrobat Pro 9 / Advanced / PDF Optimizer
!! Table~\ref{tab:eff-pdfe}
!! only the advanced server edition supports JBIG2

\begin{table}
\captiontop{PDF optimization efficiency
of Adobe Acrobat Pro 9}\label{tab:eff-a9}
\par\small\noindent\hfil
\advance\tabcolsep-2pt  % Prevent overfull \hbox.
\begin{tabular}{@{}lrrrr@{}}
\toprule
\emph{document} & \emph{input} & \emph{a9p4} & \emph{a9p5} & \emph{psom} \\\midrule
cff         &   521909 &   548181 &   329315 &   180987 \\
beamer1     &   832319 &   431936 &   334841 &   317351 \\
eu2006      &  8411464 &  8115676 &  7991997 &  4812306 \\
inkscape    & 18245172 & 14283567 & 13962583 & 13944481 \\
lme2006     &  2703119 &  2410603 &  2279985 &  2033582 \\
pdfref      & 32472771 & 23217668 & 20208419 & 11237663 \\
pgf2        &  3783193 &   failed &   failed &  2438261 \\
texbook     &  2280769 &  2314025 &  2150899 &  1806887 \\
tuzv        &   337764 &   344215 &   328843 &   146414 \\
\bottomrule
\end{tabular}
\par\bigskip
\par\noindent All numeric values are in bytes.
\par\noindent\emph{a9p4:} Adobe Acrobat Pro 9 creating PDF\,1.4
\par\noindent\emph{a9p5:} Adobe Acrobat Pro 9 creating PDF\,1.5
\par\noindent\emph{psom:} \cmd{pdfsizeopt.py} $+$ Multivalent
\end{table}



!! generated by pdfsizeopy.py --stats
!! inkscape: non-free book, 1st edition
!! inkscape: lots of small images
!! number of pages, number of images

\subsection{Adobe Acrobat}

See Table~\ref{tab:eff-a9}.


\begin{table}
\captiontop{PDF optimization efficiency
of Multivalent\,20060102}\label{tab:eff-multivalent}
\par\small\noindent\hfil
\advance\tabcolsep-2pt  % Prevent overfull \hbox.
\begin{tabular}{@{}lrrrr@{}}
\toprule
% !! why is Multivalent alone better on pdf_reference_1-7? what about extra
%    compression
\emph{document} & \emph{input} & \emph{multi} & \emph{psom} & \emph{pso} \\\midrule
cff         &   521909 &    181178 &    180987 &   230675 \\
beamer1     &   832319 &    341732 &    317351 &   443253 \\
eu2006      &  8411464 &   7198149 &   4812306 &  4993913 \\
inkscape    & 18245172 &  13976597 &  13944481 & 17183194 \\
lme2006     &  2703119 &   2285956 &   2033582 &  2349035 \\
pdfref      & 32472771 &  11235006 &  \emph{11237663} & 23413875 \\
pgf2        &  3783193 &   2584180 &   2438261 &  3449386 \\
texbook     &  2280769 &   2057755 &   1806887 &  1992958 \\
tuzv        &   337764 &    314508 &    146414 &   166863 \\
\bottomrule
\end{tabular}
\par\bigskip
\par\noindent All numeric values are in bytes.
\par\noindent\emph{multi:} Multivalent\,20060102 \emph{tool.pdf.Compress}
\par\noindent\emph{psom:} \cmd{pdfsizeopt.py} $+$ Multivalent
\par\noindent\emph{pso:} \cmd{pdfsizeopt.py} without Multivalent
\end{table}


\subsection{Multivalent tool.pdf.Compress}

!! licenses
!! does recompress ZIPs
!! Table~\ref{tab:eff-multivalent}
%!! Multivalent alone is better on pdf_reference_1-7
!! Example command line (creates optimized PDF as \texttt{doc-o.pdf}):
\texttt{java -cp Multivalent20060102.jar tool.pdf.Compress doc.pdf}

\subsection{pdfsizeopt.py}

!! write this
!! this is our contribution
!! explain that pdfsizeopt.py doesn't support content streams or cross-reference streams
!! efficient $\to$ effective

\cmd{pdfsizeopt.py} \cite{pdfsizeopt} was written as part of this work. Its purpose is to
implement the most common optimizations typical \TeX{} documents benefit
from, but only those which are not already done by Multivalent. As described
in Section~\ref{workflow}, to get the smallest output PDF, the optimizations
done by \cmd{pdfsizeopt.py} should be applied first, and the result should
be processed by Multivalent. Since the 20060102 version of Multivalent
optimizes images, and it replaces the image even if the optimized version is
larger than the original, one final step is needed to put those
original images back which are smaller. \cmd{pdfsizeopt.py}
implements this final step as well.

\cmd{pdfsizeopt.py} can be used as a stand-alone PDF optimizer (without
Multivalent), but the final PDF will be much smaller if Multivalent
is run as well.

\cmd{pdfsizeopt.py} implements the following optimizations: !!

\begin{description}

\item[Convert Type\,1 fonts to CFF]

\item[Unify subsets of the same CFF font]
Limitation: only for CFF (and former Type\,1) fonts.

\item[Convert inline images to objects]
Limitation: only from sam2p.

\item[Optimize individual images]
Picks the best of: \cmd{sam2p} without predictor, \cmd{sam2p} with
PNG predictor, PNGOUT, \cmd{jbig2}.
!! hard to convert a PDF image to a PNG.
!! Limitations: no CMYK, only device-specific color spaces (RGB, Gray and
   RGB-palette)

\item[Remove image duplicates]
!! based on image data

\item[Remove object duplicates]

\item[Remove unused objects]


\end{description}

Improvement possibilites:

!! concatenation

\section{Suggested PDF optimization workflow}\label{workflow}
!! use pdflatex or dvipdfmx with the right settings, use pdfsizeopt.py +
   Multivalent.

\section{Related work}\label{related-work}

An alternative document file format is DjVu (\cite{djvu,djvu-tutorial}),
whose most important limitation compared to PDF is that it doesn't support
vector graphics. Due to the sophisticated image layer separation and
compression, the size of a 600\,DPI DjVu file is comparable to the
coressponding optimized PDF document. If the PDF contains maily images (such
as a sequence of scanned sheets), the DjVu file will become slightly smaller
than the PDF file. If the PDF contains text with embedded vector fonts and
vector graphics, the DjVu file can be about 3 times larger than the PDF.
Of course these ratios depend on the software used for encoding as well.
There are only a few DjVu encoders available: \cmd{pdf2djvu} and
\cmd{djvudigital} are free, and Document\,Express is a commercial
application.

Since the DjVu file format uses very different technologies than PDF, one
can archive both the PDF and the DjVu version of the same document, in case
a decent renderer won't be available for one of the formats decades later.

!! more related work

\section{Conclusion}

!!

\section{References}

!! \cite all

!! \cite the PDF optimization article and all from info.txt

@iso-pdf{
PDF 1.7 is ISO 32000
meta-link: http://www.theinquirer.net/inquirer/news/1030411/pdf-approved-iso-32000
}

@djvu-tutorial{
http://www.djvuzone.org/support/tutorial/chapter-intro.html
}

!!
@dvipdfmx{
http://project.ktug.or.kr/dvipdfmx/
}

% !! # in the URL
@pdfsizeopt-extra{
%http://code.google.com/p/pdfsizeopt/source/browse/#svn/trunk/extra
}

% !! # in the URL
@pts-graphics-helper{
%http://code.google.com/p/pdfsizeopt/source/browse/#svn/trunk/extra
}

@pstricks-pdfoutput{
http://tug.org/PSTricks/main.cgi?file=pdf/pdfoutput
}

@pdf-enhancer{
%http://www.apagoinc.com/prod_home.php?prod_id=2
}

@example-pdfs{
http://code.google.com/p/pdfsizeopt/wiki/ExamplePDFsToOptimize
}

@pdfsizeopt{
http://code.google.com/p/pdfsizeopt
}

\end{document}
